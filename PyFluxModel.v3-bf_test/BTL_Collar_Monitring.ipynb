{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100203.241 101286.89 ]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'        [CH4]d_ppm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda2\\envs\\py3k\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2645\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2646\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '        [CH4]d_ppm'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-6a222d0ba579>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;31m#Choose data series (i.e. methane dry mole fraction and gas temperature, CH4d_ppm and GasT_C)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m \u001b[0mts\u001b[0m          \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbetween_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'        [CH4]d_ppm'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;31m#.plot()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[0mtemperature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbetween_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'        GasT_C'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;31m#.plot()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py3k\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2798\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2799\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2800\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py3k\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2646\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2648\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2650\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '        [CH4]d_ppm'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from math import *\n",
    "#########!!!INPUT!!!########!!!INPUT!!!####!!!INPUT!!!##################\n",
    "#########!!!INPUT!!!########!!!INPUT!!!####!!!INPUT!!!##################\n",
    "#Sample ID\n",
    "sample_id = '2021_03_28_Esro'\n",
    "\n",
    "# #submersion depth in water or snow (cm)\n",
    "# #If multiple measurements are used in uneven surfaces, enter them in the mean field separated by comma\n",
    "# #when not submerged, (i.e. with collars) enter \"0\"\n",
    "sub_d = np.mean([0])\n",
    "\n",
    "# #Exposed height of chamber/bucket above surface (cm)\n",
    "# #If multiple measurements are used in uneven surfaces, enter them in the mean field separated by comma\n",
    "xh = np.mean([34.5])-sub_d\n",
    "\n",
    "# #collar height above surface (cm) (for use with big chamber and collars)\n",
    "# #when partially submerged (non-collar measurements), comment out 1st \"collar_h\" (the one that subtracts the collar plunge depth, 3.53), and \n",
    "# #uncomment the 2nd \"collar_h\" with a mean of \"0\"\n",
    "#collar_h = meancollar-3.53\n",
    "collar_h = np.mean([0])\n",
    "\n",
    "#Atmospheric Pressure (inHg)\n",
    "#https://www.wunderground.com/dashboard/pws/KAKFAIRB30/graph/2019-03-6/2019-03-6/daily\n",
    "#time of pressure reading: 12:04\n",
    "#P_inHg = 29.91\n",
    "########################################################################\n",
    "\n",
    "\n",
    "#########!!!INPUT!!!########!!!INPUT!!!####!!!INPUT!!!##################\n",
    "#########!!!INPUT!!!########!!!INPUT!!!####!!!INPUT!!!##################\n",
    "#Pressure data from Big Trail Tower Data file(units of Pa)\n",
    "dfp = pd.read_csv(r'C:\\Users\\NorthSlope\\Desktop\\GEOS694_Snow\\Project\\methane-master\\inputs\\weather_data\\June2019_T_P.csv', delimiter=',', parse_dates=[['date','time']])\n",
    "P_Pa = dfp.loc[dfp['date_time'] == '6/27/2020 13:30','air_p_mean_Pa'].values\n",
    "########################################################################\n",
    "print(P_Pa)\n",
    "\n",
    "#########!!!INPUT!!!########!!!INPUT!!!####!!!INPUT!!!##################\n",
    "#########!!!INPUT!!!########!!!INPUT!!!####!!!INPUT!!!##################\n",
    "# Enter LGR data file path \n",
    "# Read the text file and select a time section\n",
    "#*****Sometimes \"index_col = 1 instead of 0\"********\n",
    "df = pd.read_csv(r'C:\\Users\\NorthSlope\\Desktop\\GEOS694_Snow\\Project\\methane-master\\inputs\\master_microLGR\\micro_2021-09-03_f0001.txt', delimiter=',', header = 1, index_col = 1)\n",
    "########################################################################\n",
    "\n",
    "\n",
    "#########!!!INPUT!!!########!!!INPUT!!!####!!!INPUT!!!##################\n",
    "#########!!!INPUT!!!########!!!INPUT!!!####!!!INPUT!!!##################\n",
    "#Start and stop time of chamber measurment in HH:MM:SS (24-hour time)\n",
    "\n",
    "time0 = \"9:22:34\"\n",
    "time1 = \"9:27:49\"\n",
    "\n",
    "########################################################################\n",
    "\n",
    "#########!!!INPUT!!!########!!!INPUT!!!####!!!INPUT!!!##################\n",
    "#########!!!INPUT!!!########!!!INPUT!!!####!!!INPUT!!!##################\n",
    "#\n",
    "# Don't forget to assign output log file at the end of this notebook!!!\n",
    "#\n",
    "########################################################################\n",
    "\n",
    "df.index = pd.DatetimeIndex(df.index)\n",
    "df.index\n",
    "df.keys()\n",
    "df.head()\n",
    "\n",
    "\n",
    "#Choose data series (i.e. methane dry mole fraction and gas temperature, CH4d_ppm and GasT_C)\n",
    "ts          = df.between_time(start_time = \"{}\".format(time0), end_time = \"{}\".format(time1))['        [CH4]d_ppm']#.plot()\n",
    "temperature = df.between_time(start_time = \"{}\".format(time0), end_time = \"{}\".format(time1))['        GasT_C']#.plot()\n",
    "print(type(ts))\n",
    "#Plot the raw LGR data for the measurement window\n",
    "ts = xr.DataArray(ts, coords = [ts.index], dims = ['time'])\n",
    "type(ts)\n",
    "print(ts)\n",
    "ts.plot()\n",
    "\n",
    "temperature_mean = xr.DataArray(temperature, coords = [temperature.index], dims = ['time']).mean().data\n",
    "temperature_error = temperature.std() + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #This section is optimized for the \"bucket chambers\" in the snow. \n",
    "# # #A snow density is assumed from literature values, and the snow water equivalent is calculated to \n",
    "# # #correct for the snow's porosity in the chamber\n",
    "# # #Conditions for snow or sediment height estimation\n",
    "if xh <= 5:\n",
    "    xh_error = xh*0.5\n",
    "else :\n",
    "     xh_error = xh*0.2\n",
    "\n",
    "# #Chamber dimensions for white buckets (units of cm)\n",
    "h = 34.5\n",
    "diam_top = 25.8\n",
    "r_top = diam_top/2\n",
    "\n",
    "# #\"bottom\" here is actually the top of the bucket. Because when modelling a truncated cone, it's \n",
    "# #easier to think of the bottom as the base with the larger radius\n",
    "diam_bottom = 29\n",
    "r_bottom = diam_bottom/2\n",
    "\n",
    "# # #lid volume (cm^3)\n",
    "lid_vol = 975\n",
    "lid_vol_error = lid_vol* 0.01\n",
    "\n",
    "# # #tubing dimensions (cm, cm^3 for t_vol)\n",
    "t_length = 914.4\n",
    "t_length_error = t_length * 0.05\n",
    "t_id = 0.3175\n",
    "t_vol = pi*((t_id/2)**2)*t_length\n",
    "t_vol_error = t_length_error * abs(t_id)\n",
    "\n",
    "# # #LGR cell volume (cm^3)\n",
    "# LGR_vol = 335\n",
    "# LGR_vol_error = LGR_vol*0.01\n",
    "\n",
    "# # #Volume of Chamber (as a truncated cone) (cm^3)\n",
    "vol = pi*h*(r_bottom**2 + r_top**2 + r_bottom*r_top)/3\n",
    "\n",
    "# # #Normal Height (height from center of bottom base to apex of the imaginary cone) (cm)\n",
    "n_height = h + ((h*r_top)/(r_bottom - r_top))\n",
    "\n",
    "# # #Volume of Normal cone (if chamber were not truncated, i.e. bucket-shaped)(cm^3)\n",
    "cone_volume = (1/3)*pi*(r_bottom**2)*n_height\n",
    "\n",
    "# # #Volume of the imaginary cone (the volume that is removed/truncated to form the bucket shape)(cm^3)\n",
    "imagine_volume = (1/3)*pi*(r_top**2)*(n_height - h)\n",
    "\n",
    "# # #Hypotenuse of Normal cone (cm)\n",
    "hypo_cone = sqrt((r_bottom**2)+(n_height**2))\n",
    "\n",
    "# #angle of normal cone apothems (radians)\n",
    "angle = (asin(r_bottom/hypo_cone))*2\n",
    "\n",
    "# # #Normal height of Snow Cone (cm)\n",
    "n_height_snow = (n_height - h) + (h - xh)\n",
    "n_height_snow_error = xh_error\n",
    "\n",
    "# # #exterior angle *between snow level and the side of bucket (downward) (degrees)\n",
    "ex_angle = 180 - ((angle*(180/pi))/2) - 90\n",
    "\n",
    "# # #Hypotenuse of Snow cone (cm)\n",
    "hypo_snow = (n_height_snow/cos(angle/2))\n",
    "hypo_snow_error = n_height_snow_error*abs((cos(angle/2)))\n",
    "\n",
    "# # #Radius of top of snow (cm)\n",
    "r_snow = sqrt((hypo_snow**2)-(n_height_snow**2))\n",
    "r_snow_error = 2*(hypo_snow_error/abs(hypo_snow))*abs(r_snow) + 2*(n_height_snow_error/abs(n_height_snow))*abs(r_snow)\n",
    "\n",
    "# # #Volume of snow cone (cm^3)\n",
    "snow_cone_volume = (1/3)*pi*(r_snow**2)*(n_height_snow)\n",
    "snow_cone_volume_error = (sqrt((r_snow_error/r_snow)**2 + (n_height_snow_error/n_height_snow)**2))*abs(pi/3)\n",
    "\n",
    "# # #Uncorrected Volume of Snow in Chamber (non-porous snow) (cm^3)\n",
    "un_snow_vol = snow_cone_volume - imagine_volume\n",
    "un_snow_vol_error = snow_cone_volume_error\n",
    "\n",
    "# # #Snow bulk density (g/cm^3) Sturm et al. 2010 Journal of Hydrometeorology\n",
    "# # #Mean = 0.217 g/cm^3 Taken from 1541 observations in Alaskan/Canadian Taiga\n",
    "# # #Std = 0.056 g/cm^3 \n",
    "pb = 0.217\n",
    "pb_error = 0.056\n",
    "\n",
    "# # #Snow water equivalent (cm)\n",
    "swe = (h - xh)*(pb/1)\n",
    "swe_error = sqrt((xh_error/xh)**2 + (pb_error/pb)**2)\n",
    "\n",
    "# # #Corrected volume of snow (cylinder since \"top\" base of bucket is pushed into snow)(cm^3)\n",
    "corrected_snow_vol = pi*(r_top**2)*swe\n",
    "corrected_snow_vol_error = swe_error *abs(pi*(r_top**2))\n",
    "\n",
    "# #Total volume(cm^3)\n",
    "total_vol = vol -un_snow_vol + lid_vol + t_vol + LGR_vol\n",
    "total_vol_error = un_snow_vol_error + lid_vol_error + t_vol_error + LGR_vol_error\n",
    "\n",
    "# # #Total volume corrected (accounting for swe-based snow volume)(cm^3)\n",
    "total_vol_corr = vol - corrected_snow_vol + lid_vol + t_vol + LGR_vol\n",
    "total_vol_corr_error = corrected_snow_vol_error + lid_vol_error+ t_vol_error + LGR_vol_error\n",
    "\n",
    "# # #Convert total corrected volume to liters (L)\n",
    "V = total_vol_corr / 1000\n",
    "V_error = total_vol_corr_error / 1000\n",
    "\n",
    "# # #Surface area of chamber opening (m^2)\n",
    "area = pi*(r_top**2)/10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'r_top' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-381838d0102d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;31m#Corrected volume of snow (cylinder since \"top\" base of bucket is pushed into snow)(cm^3)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m \u001b[0mcorrected_snow_vol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr_top\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mswe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[0mcorrected_snow_vol_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mswe_error\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr_top\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'r_top' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# #Chamber dimensions for white buckets (units of cm)\n",
    "# h = 34.5\n",
    "# diam_top = 25.8\n",
    "# r_top = diam_top/2\n",
    "\n",
    "# # \"bottom\" here is actually the top of the bucket. Because when modelling a truncated cone, it's \n",
    "# # easier to think of the bottom as the base with the larger radius\n",
    "# diam_bottom = 29\n",
    "# r_bottom = diam_bottom/2\n",
    "\n",
    "# #lid volume (cm^3)\n",
    "# lid_vol = 975\n",
    "# lid_vol_error = lid_vol* 0.01\n",
    "\n",
    "# #tubing dimensions (cm, cm^3 for t_vol)\n",
    "# t_length = 914.4\n",
    "# t_length_error = t_length * 0.05\n",
    "# t_id = 0.3175\n",
    "# t_vol = pi*((t_id/2)**2)*t_length\n",
    "# t_vol_error = t_length_error * abs(t_id)\n",
    "\n",
    "# #LGR cell volume (cm^3)\n",
    "# LGR_vol = 335\n",
    "# LGR_vol_error = LGR_vol*0.01\n",
    "\n",
    "# #Volume of Chamber (as a truncated cone) (cm^3)\n",
    "# vol = pi*h*(r_bottom**2 + r_top**2 + r_bottom*r_top)/3\n",
    "\n",
    "# #Normal Height (height from center of bottom base to apex of the imaginary cone) (cm)\n",
    "# n_height = h + ((h*r_top)/(r_bottom - r_top))\n",
    "\n",
    "# #Volume of Normal cone (if chamber were not truncated, i.e. bucket-shaped)(cm^3)\n",
    "# cone_volume = (1/3)*pi*(r_bottom**2)*n_height\n",
    "\n",
    "# #Volume of the imaginary cone (the volume that is removed/truncated to form the bucket shape)(cm^3)\n",
    "# imagine_volume = (1/3)*pi*(r_top**2)*(n_height - h)\n",
    "\n",
    "# #Hypotenuse of Normal cone (cm)\n",
    "# hypo_cone = sqrt((r_bottom**2)+(n_height**2))\n",
    "\n",
    "# #angle of normal cone apothems (radians)\n",
    "# angle = (asin(r_bottom/hypo_cone))*2\n",
    "\n",
    "# #Normal height of sediment Cone (cm)\n",
    "# n_height_sed = (n_height - h) + (h - xh)\n",
    "# n_height_sed_error = xh_error\n",
    "\n",
    "# #exterior angle *between sediment level and the side of bucket (downward) (degrees)\n",
    "# ex_angle = 180 - ((angle*(180/pi))/2) - 90\n",
    "\n",
    "# #Hypotenuse of sediment cone (cm)\n",
    "# hypo_sed = (n_height_sed/cos(angle/2))\n",
    "# hypo_sed_error = n_height_sed_error*abs((cos(angle/2)))\n",
    "\n",
    "# #Radius of top of sediment (cm)\n",
    "# r_sed = sqrt((hypo_sed**2)-(n_height_sed**2))\n",
    "# r_sed_error = 2*(hypo_sed_error/abs(hypo_sed))*abs(r_sed) + 2*(n_height_sed_error/abs(n_height_sed))*abs(r_sed)\n",
    "\n",
    "# #Volume of sediment cone (cm^3)\n",
    "# sed_cone_volume = (1/3)*pi*(r_sed**2)*(n_height_sed)\n",
    "# sed_cone_volume_error = (sqrt((r_sed_error/r_sed)**2 + (n_height_sed_error/n_height_sed)**2))*abs(pi/3)\n",
    "\n",
    "# #Uncorrected Volume of sediment in Chamber (non-porous snow) (cm^3)\n",
    "# un_sed_vol = sed_cone_volume - imagine_volume\n",
    "# un_sed_vol_error = sed_cone_volume_error\n",
    "\n",
    "#Snow bulk density (g/cm^3) Sturm et al. 2010 Journal of Hydrometeorology\n",
    "#Mean = 0.217 g/cm^3 Taken from 1541 observations in Alaskan/Canadian Taiga\n",
    "#Std = 0.056 g/cm^3\n",
    "pb = 0.217\n",
    "pb_error = 0.056\n",
    "\n",
    "#Snow water equivalent (cm)\n",
    "swe = (h - xh)*(pb/1)\n",
    "swe_error = sqrt((xh_error/xh)**2 + (pb_error/pb)**2)\n",
    "\n",
    "#Corrected volume of snow (cylinder since \"top\" base of bucket is pushed into snow)(cm^3)\n",
    "corrected_snow_vol = pi*(r_top**2)*swe\n",
    "corrected_snow_vol_error = swe_error *abs(pi*(r_top**2))\n",
    "\n",
    "# #Total volume(cm^3)\n",
    "total_vol = vol -un_sed_vol + lid_vol + t_vol + LGR_vol\n",
    "total_vol_error = un_sed_vol_error + lid_vol_error + t_vol_error + LGR_vol_error\n",
    "\n",
    "# #Total volume corrected (accounting for swe-based snow volume)(cm^3)\n",
    "total_vol_corr = vol - corrected_snow_vol + lid_vol + t_vol + LGR_vol\n",
    "total_vol_corr_error = corrected_snow_vol_error + lid_vol_error+ t_vol_error + LGR_vol_error\n",
    "\n",
    "# #Convert total corrected volume to liters (L)\n",
    "# V = total_vol / 1000\n",
    "# V_error = total_vol_error / 1000\n",
    "\n",
    "#Surface area of chamber opening (m^2)\n",
    "#area = pi*(r_top**2)/10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section is optimized for the \"large square chambers\" rested on aluminum collar locations. \n",
    "# density calculations are not required \n",
    "\n",
    "#Chamber dimensions for large clear chamber (units of cm)\n",
    "h = 106.5 - sub_d\n",
    "w = 65.7\n",
    "d = 65.7\n",
    "vol = h*w*d\n",
    "vol_error = vol * 0.05\n",
    "xh = h + collar_h\n",
    "\n",
    "#Collar dimensions (units of cm)\n",
    "collar_w = 70.7\n",
    "collar_d = 70.7\n",
    "collar_vol = collar_h*collar_w*collar_d\n",
    "collar_vol_error = collar_vol * 0.05\n",
    "\n",
    "#tubing dimensions (cm, cm^3 for t_vol)\n",
    "t_length = 914.4\n",
    "t_length_error = t_length * 0.05\n",
    "t_id = 0.3175\n",
    "t_vol = pi*((t_id/2)**2)*t_length\n",
    "t_vol_error = t_length_error * abs(t_id)\n",
    "\n",
    "#LGR cell volume (cm^3)\n",
    "LGR_vol = 335\n",
    "LGR_vol_error = LGR_vol*0.01\n",
    "\n",
    "#Snow bulk density (g/cm^3) Sturm et al. 2010 Journal of Hydrometeorology\n",
    "#Mean = 0.217 g/cm^3 Taken from 1541 observations in Alaskan/Canadian Taiga\n",
    "#Std = 0.056 g/cm^3\n",
    "pb = 0.217\n",
    "pb_error = 0.056\n",
    "\n",
    "#Snow water equivalent (cm)\n",
    "swe = (h - xh)*(pb/1)\n",
    "swe_error = sqrt((xh_error/xh)**2 + (pb_error/pb)**2)\n",
    "\n",
    "#Corrected volume of snow (cylinder since \"top\" base of bucket is pushed into snow)(cm^3)\n",
    "corrected_snow_vol = pi*(r_top**2)*swe\n",
    "corrected_snow_vol_error = swe_error *abs(pi*(r_top**2))\n",
    "\n",
    "#Total volume(cm^3)\n",
    "total_vol = vol + t_vol + LGR_vol + collar_vol\n",
    "total_vol_error = vol_error + t_vol_error + LGR_vol_error + collar_vol_error\n",
    "\n",
    "#Convert total corrected volume to liters (L)\n",
    "V = total_vol / 1000\n",
    "V_error = total_vol_error / 1000\n",
    "\n",
    "#Surface area of collar opening (m^2)\n",
    "area = (collar_w*collar_d)/10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volume =  460.11358083107615  ± 23.003175350000006  liters\n"
     ]
    }
   ],
   "source": [
    "# As a sanity check, print the volume of the chamber/bucket and it's error in liters\n",
    "print('volume = ', V, ' ±',  V_error,  ' liters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: \n",
    "We find sections in the observation window which are\n",
    "1. at least 50 seconds long and no more than 210 (50 < n > 210)\n",
    "2. the linear slope of the section should fit the data with R2 0.985. WHich means 98% of the variation in data can be explained by our model. \n",
    "\n",
    "Algorithm:\n",
    "We start with a section of first 210 points from the section window. We fit a line to the section and compute the errors as the squareroot of the diagnols of the covariance matrix between the model and data. We also compute R2 between the slope and the data and if R2 is greater than 0.985, we stop, since we got the largest continuous section which fulfils the requirement. i.e. our best case scenario! If we don't get a valid slope value, we shift the section by 1. i.e. from the second element to 211th element in the section window and repeat the process. If we don't get a valid slope even after shifting through the entire length of the section window, we reduce the section length to 209 and start sliding. So on until we reduce the section length to its lowest threshold, i.e. 50. \n",
    "\n",
    "If we still don't get a valid value for the smallest section, we start smoothing the sections by 5, 10, and ultimately 15-point moving windows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[]\n",
    "\n",
    "def compute_r2(ts_section, plot = False):\n",
    "     x     = np.arange(len(ts_section))\n",
    "     #removes time metadata for simplicity\n",
    "     y     = np.array(ts_section)\n",
    "     model = np.polyfit(x,y,1)\n",
    "     slope = model[0]\n",
    "     intercept = model[1]\n",
    "     y_hat = slope*x + intercept # OR np.polyval(model, x)\n",
    "     correlation_coefficient = np.corrcoef(y,y_hat)[0,1]\n",
    "     r_square = (correlation_coefficient)**2\n",
    "     if plot:\n",
    "         plt.plot(y)\n",
    "         plt.plot(y_hat)\n",
    "\n",
    "     return r_square, slope\n",
    "def brain(section_length, ts):\n",
    "    for section_length in section_length:\n",
    "        # print(section_length)\n",
    "        r_2 = []\n",
    "        slope = []\n",
    "        start = []\n",
    "        # end   = []\n",
    "        # section_length = 210\n",
    "        for i in range(len(ts)-section_length):\n",
    "            ts_section = ts[i:i + section_length]\n",
    "            tmp_start  = ts_section.time[0]\n",
    "            tmp_end    = ts_section.time[-1]\n",
    "            tmp_r2, tmp_slope = compute_r2(ts_section, plot=False)\n",
    "            r_2.append(tmp_r2)\n",
    "            slope.append(tmp_slope)\n",
    "            start.append(tmp_start)\n",
    "            # end.append(tmp_end)\n",
    "\n",
    "        r_2 = xr.DataArray(r_2, coords = [ts[:-int(section_length)].time], dims = ['time'])\n",
    "        slope = xr.DataArray(slope, coords = [ts[:-int(section_length)].time], dims = ['time'])\n",
    "        # end = xr.DataArray(end, coords = [ts[:-int(section_length)].time], dims = ['time'])\n",
    "        # start = xr.DataArray(start, coords = [ts[:-int(section_length)].time], dims = ['time'])\n",
    "        # just select those r2s that qualify the threshold, drop the rest to get time stamp\n",
    "\n",
    "        # c = end.where(r_2>=r_2_threshold, drop=True)\n",
    "        #\n",
    "\n",
    "        a = list(slope.where(r_2>=r_2_threshold, drop=True))\n",
    "        R_squared = list(r_2.where(r_2>=r_2_threshold, drop=True))\n",
    "        result = []\n",
    "        valid_length = []\n",
    "        if a:\n",
    "            # print(a)\n",
    "            result = a[0].data\n",
    "            valid_length = section_length\n",
    "            # print('starting time stamp' + a[0].time)\n",
    "            break\n",
    "\n",
    "        # ts.sel(time=slice(b[0],c[0]))\n",
    "        # ts.plot()\n",
    "        # ts.loc[a.time.values].plot()\n",
    "        #\n",
    "        # np.where(ts.index==a.time[0])\n",
    "    return valid_length, result, a, R_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020_06-27_BTL_eastside\n",
      "valid section length = 210.000\n",
      "Smoothing_window = 5.000\n"
     ]
    }
   ],
   "source": [
    "print(sample_id)\n",
    "\n",
    "#########!!!INPUT!!!########!!!INPUT!!!####!!!INPUT!!!##################\n",
    "#########!!!INPUT!!!########!!!INPUT!!!####!!!INPUT!!!##################\n",
    "# Set data quality thresholds\n",
    "min_section_length_original = 45\n",
    "max_section_length = 210\n",
    "r_2_threshold = 0.985\n",
    "#starting smoothing window\n",
    "smoothing_window = 0\n",
    "########################################################################\n",
    "\n",
    "section_length   = np.arange(min_section_length_original,max_section_length+1)[::-1]\n",
    "valid_section_length, slope, a, R_squared = brain(section_length, ts)\n",
    "if slope:\n",
    "                print('valid section length = %.3f' %valid_section_length)\n",
    "                print('Smoothing_window = %.3f' %smoothing_window)\n",
    "#                 print('Slope = %.4f' %slope)\n",
    "#                 print('Temperature = %.3f' %temperature_mean)\n",
    "#                 print('Section start timestamp = ' +str(a[0].time.data))\n",
    "else:\n",
    "    smoothing_window  = 5\n",
    "    min_section_length = min_section_length_original*2\n",
    "    section_length   = np.arange(min_section_length,max_section_length+1)[::-1]\n",
    "    ts_smooth = ts.rolling(time = smoothing_window, center = True).mean().dropna(dim='time')\n",
    "    valid_section_length, slope, a, R_squared = brain(section_length, ts_smooth)\n",
    "    if slope:\n",
    "                print('valid section length = %.3f' %valid_section_length)\n",
    "                print('Smoothing_window = %.3f' %smoothing_window)\n",
    "#                 print('Slope = %.4f' %slope)\n",
    "#                 print('Temperature = %.3f' %temperature_mean)\n",
    "#                 print('Section start timestamp = ' +str(a[0].time.data))    \n",
    "    else:\n",
    "        smoothing_window  = 10\n",
    "        min_section_length = int(min_section_length_original*2)\n",
    "        section_length   = np.arange(min_section_length,max_section_length+1)[::-1]\n",
    "        ts_smooth = ts.rolling(time = smoothing_window, center = True).mean().dropna(dim='time')\n",
    "        valid_section_length, slope, a, R_squared = brain(section_length, ts_smooth)\n",
    "        if slope:\n",
    "                print('valid section length = %.3f' %valid_section_length)\n",
    "                print('Smoothing_window = %.3f' %smoothing_window)\n",
    "#                 print('Slope = %.4f' %slope)\n",
    "#                 print('Temperature = %.3f' %temperature_mean)\n",
    "#                 print('Section start timestamp = ' +str(a[0].time.data))        \n",
    "        else:\n",
    "            smoothing_window  = 15\n",
    "            min_section_length = min_section_length_original*3\n",
    "            section_length   = np.arange(min_section_length,max_section_length+1)[::-1]\n",
    "            ts_smooth = ts.rolling(time = smoothing_window, center = True).mean().dropna(dim='time')\n",
    "            valid_section_length, slope, a, R_squared = brain(section_length, ts_smooth)\n",
    "            if slope:\n",
    "                print('valid section length = %.3f' %valid_section_length)\n",
    "                print('Smoothing_window = %.3f' %smoothing_window)\n",
    "#                 print('Slope = %.4f' %slope)\n",
    "#                 print('Temperature = %.3f' %temperature_mean)\n",
    "#                 print('Section start timestamp = ' +str(a[0].time.data))\n",
    "            else:\n",
    "                print('Oh no, bad data! Go back to field!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the 'good' section and slope error\n",
    "def get_slope_error(ts_section, plot = True):\n",
    "     x     = np.arange(len(ts_section))\n",
    "     #removes time metadata for simplicity\n",
    "     y     = np.array(ts_section)\n",
    "     model, M = np.polyfit(x,y,1, cov = True)\n",
    "     slope = model[0]\n",
    "     slope_error = np.sqrt(M[0][0])\n",
    "     intercept = model[1]\n",
    "     y_hat = slope*x + intercept # OR np.polyval(model, x)\n",
    "\n",
    "     if plot:\n",
    "            print('Slope error = %.6f ppm/s' %slope_error)\n",
    "#             plt.figure(figsize = (10,8))\n",
    "#             plt.plot(ts_section.time, y)\n",
    "#             plt.plot(ts_section.time, y_hat)\n",
    "     return slope, slope_error, ts_section, y, y_hat\n",
    "\n",
    "print(sample_id)\n",
    "print('valid section length = %d' %valid_section_length)\n",
    "print('Smoothing_window = %d' %smoothing_window)\n",
    "print('Slope = %.5f ppm/s' %slope)\n",
    "print('R^2 = %.4f ' %R_squared[0].data)\n",
    "print('Temperature = %.3f deg. C' %temperature_mean)\n",
    "print('Section start timestamp = ' +str(a[0].time.data))\n",
    "\n",
    "#Convert the section start time from datetime stamp to actual index of the original section window.\n",
    "index = np.where(ts.time ==a[0].time)[0][0]\n",
    "slope, slope_error, ts_section, y, y_hat = get_slope_error(ts[index: index+valid_section_length], plot = True)\n",
    "#print('Slope error = %.6f ppm/s' %slope_error)\n",
    "\n",
    "#Calculate Flux and its +/- uncertainty (micromoles m^-2 s^-1)\n",
    "#Gas Constant L atm mol^-1 K^-1\n",
    "#pressure in atmospheres (atm)\n",
    "P = 9.86923e-6 * P_Pa\n",
    "P_error = P * 0.01\n",
    "R = 0.082057338\n",
    "moles = (P*V)/(R*(temperature_mean+273.15))\n",
    "moles_error = sqrt((P_error/P)**2 + (V_error/V)**2 + (temperature_error/(temperature_mean+273.15)**2))\n",
    "flux = slope*moles/area\n",
    "flux_error = (sqrt(slope_error/abs(slope))**2 + (moles_error/moles)**2)\n",
    "print('Flux = %.3f ' %flux + '± %.3f ' %flux_error)\n",
    "#print('Flux Error = ± %.3f ' %flux_error)\n",
    "print('Units = micromol CH4 m^-2 s^-1')\n",
    "\n",
    "#make the Figure\n",
    "figure, ax = plt.subplots(figsize = (10,8))\n",
    "ax.plot(ts_section.time, y)\n",
    "ax.plot(ts_section.time, y_hat)\n",
    "plt.ylabel('PPM CH4_$', fontsize = 12)\n",
    "plt.xlabel('Time',fontsize = 12)\n",
    "legend = plt.legend(('Raw Data', 'Linear Fit'), title = sample_id, loc='upper left', fontsize = 12, shadow=True)\n",
    "plt.setp(legend.get_title(),fontsize='large', fontweight = 'bold')\n",
    "plt.text(0.02,0.7, 'Flux = %.3f ± %.3f \\nmicromol $CH_4$ $m^{-2}$ $s^{-1}$ \\nR$^2$ = %.3f' %(flux, flux_error,R_squared[0].data), fontsize = 13, transform=ax.transAxes)\n",
    "\n",
    "# #save the figure. \n",
    "# #########!!!INPUT!!!########!!!INPUT!!!####!!!INPUT!!!##################\n",
    "# #########!!!INPUT!!!########!!!INPUT!!!####!!!INPUT!!!##################\n",
    "plt.savefig((Path(r'C:\\Users\\Simon\\Documents\\methane\\_' + sample_id + '.png'),'dpi = 300', 'bbox_inches = tight'))\n",
    "# ########################################################################\n",
    "# print('xh = %.1f' %xh)\n",
    "# Out put the data from the computation. \n",
    "# With each program iteration, the results from the computation are saved into the space-delimited\n",
    "# .txt file specified below (i.e. \"July2019FluxData.txt\")\n",
    "# output variables to save into the output log file\n",
    "# output_data = [sample_id,temperature_mean,P[0],area,V,xh,valid_section_length,smoothing_window,slope,slope_error,R_squared[0].data,str(a[0].time.data),flux[0],flux_error[0]]\n",
    "#########!!!INPUT!!!########!!!INPUT!!!####!!!INPUT!!!##################\n",
    "#########!!!INPUT!!!########!!!INPUT!!!####!!!INPUT!!!##################\n",
    "\n",
    "            \n",
    "with open(r'C:\\Users\\Simon\\Documents\\methane\\OutputData_newtry.txt',\"at\") as f:\n",
    "    f.write('\\n')\n",
    "    np.savetxt(f, output_data, fmt=\"%s\", delimiter=' ', newline=' ')\n",
    "# ########################################################################  \n",
    "# print(output_data)\n",
    "# use this space delimited text (staring with \"Sample_ID\") to fill in the header line once time after the file is generated\n",
    "# for the first time.\n",
    "# NOTE: The header labels must be in the same order as the data in the \"output_data\" array:\n",
    "# Sample_ID Temp_C P_atm Area_m2 ChamberVol_L Chamber_height_cm valid_section_seconds smoothing_seconds slope_ppm_-s slope_error Rsquared Start_time flux_umol_m-2_s flux_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2020_07-30_Vault-Lake_Buckt-T1', array(29.39231539), 0.9765988463627656, 0.05227924334838775, 21.748288570762956, 34.5, 137, 0, array(0.12457911), 0.0013145489768308742, array(0.98519128), '2020-07-30T17:13:02.506000000', 2.0387015767445633, 0.010706854423231146]\n"
     ]
    }
   ],
   "source": [
    "# Out put the data from the computation. \n",
    "# With each program iteration, the results from the computation are saved into the space-delimited\n",
    "# .txt file specified below (i.e. \"July2019FluxData.txt\")\n",
    "\n",
    "# output variables to save into the output log file\n",
    "output_data = [sample_id,temperature_mean,P[0],area,V,xh,valid_section_length,smoothing_window,slope,slope_error,\n",
    "               R_squared[0].data,str(a[0].time.data),flux[0],flux_error[0]]\n",
    "\n",
    "#########!!!INPUT!!!########!!!INPUT!!!####!!!INPUT!!!##################\n",
    "#########!!!INPUT!!!########!!!INPUT!!!####!!!INPUT!!!##################\n",
    "with open(r'C:\\Users\\Simon\\Documents\\methane\\OutputData_newtry.txt',\"at\") as f:\n",
    "    f.write('\\n')\n",
    "    np.savetxt(f, output_data, fmt=\"%s\", delimiter=' ', newline=' ')\n",
    "########################################################################\n",
    "    \n",
    "print(output_data)\n",
    "    \n",
    "# use this space delimited text (staring with \"Sample_ID\") to fill in the header line once time after the file is generated\n",
    "# for the first time.\n",
    "# NOTE: The header labels must be in the same order as the data in the \"output_data\" array:\n",
    "\n",
    "# Sample_ID Temp_C P_atm Area_m2 ChamberVol_L Chamber_height_cm valid_section_seconds smoothing_seconds slope_ppm_-s slope_error Rsquared Start_time flux_umol_m-2_s flux_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
